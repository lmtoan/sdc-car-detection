{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "Link to Pickle files: https://www.dropbox.com/s/rfl7h55k6bb26xr/car_dataset.p?dl=0\n",
    "\n",
    "## Import & Visualize\n",
    "\n",
    "car_dataset = pickle.load(open(\"car_dataset.p\", \"rb\"))\n",
    "cars, notcars = np.asarray(car_dataset['car']), np.asarray(car_dataset['noncar'])\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for i, img in enumerate(cars[np.random.randint(len(cars), size=5)]):   \n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "for i, img in enumerate(notcars[np.random.randint(len(cars), size=5)]):   \n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# 1. Train a car classifier \n",
    "\n",
    "### HOG Features\n",
    "\n",
    "from skimage.feature import hog\n",
    "def get_hog(img, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(3, 3), vis=False):\n",
    "    \"\"\"Extract HOG features from a channel\n",
    "    \n",
    "    skimage.feature.hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(3, 3), \n",
    "    block_norm=None, visualize=False, visualise=None, transform_sqrt=False, feature_vector=True, multichannel=None)\n",
    "    \n",
    "    out : (n_blocks_row, n_blocks_col, n_cells_row, n_cells_col, n_orient) ndarray\n",
    "    HOG descriptor for the image. If feature_vector is True, a 1D (flattened) array is returned.\n",
    "\n",
    "    hog_image : (M, N) ndarray, optional\n",
    "    A visualisation of the HOG image. Only provided if visualize is True.\n",
    "    \"\"\"\n",
    "    if vis:\n",
    "        hog_features, hog_image = hog(img, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block, visualise=vis)\n",
    "        plt.figure()\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(hog_image, cmap='gray')\n",
    "        plt.show()\n",
    "        return hog_features\n",
    "    else:\n",
    "        return hog(img, orientations=orientations, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block)\n",
    "    \n",
    "def dense_SIFT(image, density=0.05, display=False):\n",
    "    \"\"\"Generate dense SIFT descriptors\n",
    "    Args:\n",
    "      image: A numpy array representing the image, which is of type np.int in range [0, 255] of size\n",
    "             (H x W x 3) in RGB order (eg. output of cv2.imread).\n",
    "      density: Decide the density of the descriptors.\n",
    "\n",
    "    Returns:\n",
    "      result: A one level 128-dimension list with the mean description value of total descriptors.\n",
    "    \"\"\"\n",
    "    # Convert into gray pic\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).astype(np.uint8)\n",
    "    # Generate a sift to calculate description vector later\n",
    "    sift = cv2.xfeatures2d.SIFT_create()\n",
    "\n",
    "    # The step to evenly pick the description point\n",
    "    # Use the short side len multiply density\n",
    "    step_size = round(min(image.shape[0], image.shape[1]) * density)\n",
    "\n",
    "    # Calculate the points with step_size\n",
    "    kp = [cv2.KeyPoint(x, y, step_size) for y in range(0, gray.shape[0], step_size)\n",
    "          for x in range(0, gray.shape[1], step_size)]\n",
    "\n",
    "    # Calculate the description vector for each points\n",
    "    dense_feat = sift.compute(gray, kp)\n",
    "\n",
    "    # Without flattening\n",
    "    # return dense_feat[1]\n",
    "    \n",
    "    if display:\n",
    "        cv2.drawKeypoints(gray, kp, image, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "        plt.figure()\n",
    "        plt.imshow(image[:, :, ::-1])\n",
    "        plt.show()\n",
    "\n",
    "    # Flatten the n description vectors, n for the num of description points\n",
    "    return np.mean(dense_feat[1], axis=0)\n",
    "\n",
    "# Red Channel\n",
    "_ = get_hog(cars[100][:,:,0], vis=True)\n",
    "# Blue Channel\n",
    "_ = get_hog(notcars[200][:,:,1], vis=True)\n",
    "# Green Channel\n",
    "_ = get_hog(cars[300][:,:,2], vis=True)\n",
    "\n",
    "# Y Channel\n",
    "_ = get_hog(cv2.cvtColor(cars[100], cv2.COLOR_RGB2YUV)[:,:,0], vis=True)\n",
    "# U Channel\n",
    "_ = get_hog(cv2.cvtColor(notcars[200], cv2.COLOR_RGB2YUV)[:,:,1], vis=True)\n",
    "# V Channel\n",
    "_ = get_hog(cv2.cvtColor(cars[300], cv2.COLOR_RGB2YUV)[:,:,2], vis=True)\n",
    "\n",
    "sift_f = dense_SIFT(cv2.imread(\"bbox-example-image.jpg\"), display=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
